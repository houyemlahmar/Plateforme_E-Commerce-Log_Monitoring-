# Plateforme de Monitoring et Analyse de Logs E-Commerce

## üìã Description

Plateforme compl√®te de centralisation, indexation et visualisation de logs pour une plateforme e-commerce traitant des milliers de commandes quotidiennes.

## üèóÔ∏è Architecture

### Stack Technologique
- **Backend**: Flask (Python)
- **Indexation & Recherche**: Elasticsearch
- **Collecte de logs**: Logstash
- **Visualisation**: Kibana
- **Cache**: Redis
- **Base de donn√©es**: MongoDB
- **Conteneurisation**: Docker & Docker Compose

### Types de Logs Trait√©s
1. **Logs de transactions** - Paiements, commandes, remboursements
2. **Logs d'erreurs applicatives** - Codes 404, 500, timeouts
3. **Logs de comportement utilisateur** - Navigation, paniers, abandons
4. **Logs de performance** - Temps de r√©ponse API, latence BDD
5. **Logs de fraude** - Tentatives suspectes, d√©tection de bots

## üöÄ D√©marrage Rapide

### Pr√©requis (Windows)
- **Docker Desktop** pour Windows (avec WSL2 activ√©)
- **Python 3.11+** (version 3.13 recommand√©e)
- **PowerShell 5.1+** ou PowerShell Core
- **Git** pour Windows
- Au minimum **8 GB RAM** (16 GB recommand√© pour l'ensemble des services)

### Installation

#### 1. D√©marrer l'infrastructure Docker

```powershell
# Cloner le projet
git clone <repository-url>
cd projet_bigdata

# D√©marrer tous les services avec Docker Compose
docker-compose up -d

# V√©rifier que tous les services sont actifs (attendez ~30 secondes)
docker-compose ps
```

**Services d√©marr√©s** :
- Elasticsearch (port 9200) - Indexation et recherche
- Flask API (port 5001) - API REST ‚ö†Ô∏è **Port 5001 au lieu de 5000** (conflit r√©solu)
- Kibana (port 5601) - Visualisation
- Logstash (port 5000) - Collecte TCP/UDP
- MongoDB (port 27017) - M√©tadonn√©es
- Redis (port 6379) - Cache

#### 2. Configuration locale (optionnel - pour d√©veloppement)

```powershell
# Cr√©er un environnement virtuel Python
cd backend
python -m venv venv

# Activer l'environnement (PowerShell)
.\venv\Scripts\Activate.ps1

# Installer les d√©pendances minimales
pip install -r requirements-minimal.txt

# Lancer Flask en mode d√©veloppement (port 5002)
$env:FLASK_APP="main.py"
python -m flask run --host=0.0.0.0 --port=5002
```

#### 3. G√©n√©rer des logs de test

```powershell
# G√©n√©rer 100 logs d'exemple
python scripts/generate_sample_logs.py -n 100

# Les logs sont cr√©√©s dans scripts/sample_logs.json
```

#### 4. Initialiser Elasticsearch (optionnel)

```powershell
# Cr√©er les index avec les mappings appropri√©s
python scripts/setup_elasticsearch.py
```

## üìÅ Structure du Projet

```
projet_bigdata/
‚îú‚îÄ‚îÄ backend/                 # Application Flask
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/         # Endpoints API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Logique m√©tier
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/         # Mod√®les de donn√©es
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/          # Utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ tests/              # Tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ infra/                  # Configuration infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ elasticsearch/
‚îÇ   ‚îú‚îÄ‚îÄ logstash/
‚îÇ   ‚îî‚îÄ‚îÄ kibana/
‚îú‚îÄ‚îÄ scripts/                # Scripts d'automatisation
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îî‚îÄ‚îÄ uploads/                # Fichiers de logs upload√©s
```

## üîß Configuration

Modifier le fichier `.env` avec vos param√®tres :
- Configuration Elasticsearch
- Configuration MongoDB
- Configuration Redis
- Cl√©s API et secrets

## üìä Acc√®s aux Services

- **Flask API (Docker)**: http://localhost:5001 ‚ö†Ô∏è **Port modifi√© de 5000 ‚Üí 5001**
- **Flask API (Local Dev)**: http://localhost:5002
- **Kibana Dashboard**: http://localhost:5601
- **Elasticsearch**: http://localhost:9200
- **Logstash TCP/UDP**: localhost:5000
- **Logstash API**: http://localhost:9600
- **MongoDB**: localhost:27017
- **Redis**: localhost:6379

### Endpoints API Principaux

```powershell
# Health check
Invoke-WebRequest "http://localhost:5001/health"

# Ingest logs (POST)
Invoke-WebRequest -Uri "http://localhost:5001/api/logs/ingest" `
  -Method POST -ContentType "application/json" `
  -Body '{"type":"transaction","data":{"order_id":"12345","amount":99.99}}'

# R√©cup√©rer logs r√©cents
Invoke-WebRequest "http://localhost:5001/api/logs/recent?limit=10"

# Recherche full-text
Invoke-WebRequest "http://localhost:5001/api/search/?query=transaction"

# Dashboard overview
Invoke-WebRequest "http://localhost:5001/api/dashboard/overview"

# Types de logs disponibles
Invoke-WebRequest "http://localhost:5001/api/logs/types"
```

## üß™ Tests

```powershell
# Activer l'environnement virtuel
cd backend
.\venv\Scripts\Activate.ps1

# Installer pytest si n√©cessaire
pip install pytest

# Lancer les tests
pytest tests/ -v

# Tests avec coverage
pytest tests/ --cov=app --cov-report=html
```

## üêõ D√©pannage

### Probl√®mes Courants

**1. Logstash ne d√©marre pas**
- V√©rifiez le fichier de configuration `infra/logstash/pipelines/ecommerce-logs.conf`
- Testez la syntaxe : `docker run --rm -v "${PWD}/infra/logstash/pipelines:/usr/share/logstash/pipeline" docker.elastic.co/logstash/logstash:8.11.0 logstash -f /usr/share/logstash/pipeline/ecommerce-logs.conf --config.test_and_exit`

**2. Port 5000 d√©j√† utilis√©**
- Le port 5000 est r√©serv√© √† Logstash (TCP/UDP)
- Flask utilise le port 5001 dans Docker
- Pour d√©veloppement local, utilisez le port 5002

**3. Kibana affiche des warnings CSP**
- Ces warnings sont normaux en d√©veloppement
- Message attendu : "Content Security Policy directive 'script-src 'self'"
- Kibana fonctionne malgr√© ces avertissements

**4. Elasticsearch import errors**
- Si erreur `ElasticsearchException`, c'est corrig√© dans `app/services/elasticsearch_service.py`
- Utilisation de `Exception` au lieu de `ElasticsearchException` (API 8.11)

### Commandes de diagnostic

```powershell
# V√©rifier l'√©tat de tous les containers
docker-compose ps

# Logs d'un service sp√©cifique
docker-compose logs flask-app --tail 50
docker-compose logs elasticsearch --tail 50
docker-compose logs logstash --tail 50

# Red√©marrer un service
docker-compose restart flask-app

# Reconstruire et red√©marrer
docker-compose down
docker-compose up -d --build

# V√©rifier les index Elasticsearch
Invoke-WebRequest "http://localhost:9200/_cat/indices?v"

# Tester la connexion Elasticsearch
Invoke-WebRequest "http://localhost:9200/_cluster/health"
```

## üìñ Documentation

Consulter le dossier `docs/` pour :
- **architecture.md** - Architecture d√©taill√©e et flux de donn√©es
- **api_documentation.md** - Documentation compl√®te des endpoints (20+ routes)
- **quick_start.md** - Guide de d√©marrage rapide
- **PROJECT_SUMMARY.md** - R√©sum√© technique du projet

### Fonctionnalit√©s Impl√©ment√©es

‚úÖ **Gestion des Logs**
- Ingestion via API REST (JSON)
- Ingestion via Logstash (TCP/UDP port 5000)
- Upload de fichiers logs
- Support de 5 types de logs (transaction, error, user_behavior, performance, fraud)

‚úÖ **Recherche et Analytics**
- Recherche full-text avec Elasticsearch
- Autocompl√©tion
- Agr√©gations par type, p√©riode, statut
- Statistiques en temps r√©el

‚úÖ **Dashboard**
- Vue d'ensemble 24h
- M√©triques de performance
- Distribution des types de logs
- Alertes de fraude

‚úÖ **D√©tection de Fraude**
- Scoring automatique (0-100)
- D√©tection d'activit√©s suspectes
- 5 indicateurs de fraude

‚úÖ **Performance Monitoring**
- Temps de r√©ponse API
- Latence base de donn√©es
- Calcul de percentiles (p50, p95, p99)

## üîß Configuration Avanc√©e

### Variables d'Environnement

Cr√©er un fichier `.env` √† la racine :

```env
# Flask
FLASK_ENV=development
SECRET_KEY=your-secret-key-here

# Elasticsearch
ELASTICSEARCH_HOST=localhost
ELASTICSEARCH_PORT=9200

# MongoDB
MONGODB_HOST=localhost
MONGODB_PORT=27017
MONGODB_DB=ecommerce_logs

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0

# Logstash
LOGSTASH_HOST=localhost
LOGSTASH_PORT=5000
```

### Modifications Importantes Appliqu√©es

**Corrections de Bugs** :
1. ‚úÖ Port Flask chang√© de 5000 ‚Üí 5001 (conflit avec Logstash)
2. ‚úÖ Import Elasticsearch corrig√© (`ElasticsearchException` ‚Üí `Exception`)
3. ‚úÖ Configuration Kibana mise √† jour pour v8.11 (logging.appenders)
4. ‚úÖ Fichier Logstash pipeline reconfigur√© sans commentaires probl√©matiques
5. ‚úÖ Attribut `version` retir√© de docker-compose.yml (obsol√®te)

**Optimisations** :
- Cache Redis configur√© pour les requ√™tes
- Mappings Elasticsearch optimis√©s pour la recherche
- Geolocalization activ√©e sur les IPs
- Pipeline Logstash avec enrichissement automatique

## ü§ù Contribution

1. Fork le projet
2. Cr√©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## üìù Licence

Ce projet est sous licence MIT.

## üë• Auteur

√âquipe Infrastructure & Data Engineering
