# Ingestion Service Implementation

## ğŸ“‹ Overview

Service Python autonome qui Ã©coute la queue Redis `ingest_jobs`, dÃ©place les fichiers vers le rÃ©pertoire surveillÃ© par Logstash, et met Ã  jour les statuts dans MongoDB.

## âœ… ImplÃ©mentation ComplÃ¨te

### 1. Service Principal
**Fichier**: [`backend/ingestion_service.py`](backend/ingestion_service.py)

**FonctionnalitÃ©s**:
- âœ… Ã‰coute en continu de la liste Redis `ingest_jobs`
- âœ… DÃ©placement des fichiers vers le rÃ©pertoire Logstash (`./uploads`)
- âœ… Mise Ã  jour des statuts dans MongoDB collection `uploads`
- âœ… Logique de retry (3 tentatives par dÃ©faut, dÃ©lai 5s)
- âœ… Logging complet (fichier + console)
- âœ… Gestion gracieuse des signaux (SIGINT, SIGTERM)
- âœ… Gestion d'erreurs robuste

**Statuts MongoDB**:
- `pending` - Job crÃ©Ã©, en attente
- `processing` - En cours de traitement
- `completed` - Traitement rÃ©ussi
- `failed` - Ã‰chec aprÃ¨s tous les retries

### 2. Script de DÃ©marrage
**Fichier**: [`backend/start_ingestion_service.py`](backend/start_ingestion_service.py)

Simple wrapper pour dÃ©marrer le service avec affichage des informations.

### 3. Tests AutomatisÃ©s
**Fichier**: [`test_ingestion_service.py`](test_ingestion_service.py)

**Tests inclus**:
1. âœ… VÃ©rification statut queue Redis
2. âœ… VÃ©rification collection MongoDB `uploads`
3. âœ… CrÃ©ation fichier de test
4. âœ… Push job dans la queue
5. âœ… Workflow complet (upload API â†’ queue â†’ ingestion)

## ğŸš€ Utilisation

### DÃ©marrer le Service

```powershell
# MÃ©thode 1: Directement
cd backend
python start_ingestion_service.py

# MÃ©thode 2: Via module
cd backend
python -m ingestion_service
```

**Sortie**:
```
============================================================
Starting Ingestion Service
============================================================

This service will:
  - Listen to Redis queue 'ingest_jobs'
  - Move files to Logstash watch directory
  - Update job status in MongoDB

Press Ctrl+C to stop

============================================================
2025-12-25 10:00:00 - INFO - Ingestion Service initialized
2025-12-25 10:00:00 - INFO - Source directory: C:\projet_bigdata\uploads
2025-12-25 10:00:00 - INFO - Target directory: C:\projet_bigdata\uploads
2025-12-25 10:00:00 - INFO - Starting ingestion service listener...
```

### Tester le Service

```powershell
# Lancer les tests
python test_ingestion_service.py
```

## ğŸ”„ Workflow Complet

```
1. Upload fichier via API
   POST /api/logs/upload
   â””â”€> Fichier sauvegardÃ© dans ./uploads/TIMESTAMP_UUID_filename
   â””â”€> MÃ©tadonnÃ©es dans MongoDB collection "uploads" (status: pending)
   â””â”€> Job pusher dans Redis queue "ingest_jobs"

2. Service Ingestion (Ã©coute en continu)
   â””â”€> Pop job depuis Redis queue "ingest_jobs" (FIFO)
   â””â”€> Update status MongoDB: "processing"
   â””â”€> DÃ©place/vÃ©rifie fichier dans ./uploads (watch dir Logstash)
   â””â”€> Update status MongoDB: "completed" ou "failed"
   â””â”€> Retry automatique en cas d'Ã©chec (max 3 fois)

3. Logstash (surveillance automatique)
   â””â”€> DÃ©tecte nouveau fichier dans ./uploads
   â””â”€> Parse selon pipeline (JSON ou CSV)
   â””â”€> Index dans Elasticsearch
   â””â”€> Fichier traitÃ© reste dans ./uploads (ou archivÃ©)
```

## âš™ï¸ Configuration

### ParamÃ¨tres Service
Dans [`backend/ingestion_service.py`](backend/ingestion_service.py#L35):

```python
IngestionService(
    redis_service=redis_service,
    mongo_service=mongo_service,
    source_dir='./uploads',        # RÃ©pertoire source
    target_dir='./uploads',        # RÃ©pertoire Logstash (mÃªme dir)
    max_retries=3,                 # Nombre de retries
    retry_delay=5,                 # DÃ©lai entre retries (secondes)
    poll_interval=5                # FrÃ©quence polling queue (secondes)
)
```

### Logging
Logs Ã©crits dans:
- **Fichier**: `backend/ingestion_service.log`
- **Console**: stdout (temps rÃ©el)

Format:
```
2025-12-25 10:05:30 - ingestion_service - INFO - Processing job abc123: ./uploads/file.json
2025-12-25 10:05:31 - ingestion_service - INFO - File already in Logstash watch directory: file.json
2025-12-25 10:05:31 - ingestion_service - INFO - Job abc123 completed successfully
```

## ğŸ” Monitoring

### VÃ©rifier la Queue Redis
```powershell
# Longueur de la queue
docker-compose exec redis redis-cli -a redis_password LLEN ingest_jobs

# Voir les jobs (premiers 10)
docker-compose exec redis redis-cli -a redis_password LRANGE ingest_jobs 0 9

# Vider la queue (si nÃ©cessaire)
docker-compose exec redis redis-cli -a redis_password DEL ingest_jobs
```

### VÃ©rifier MongoDB
```powershell
# Voir tous les uploads
docker-compose exec mongodb mongosh -u admin -p mongodb_password --eval "use ecommerce_logs; db.uploads.find().pretty()"

# Compter par statut
docker-compose exec mongodb mongosh -u admin -p mongodb_password --eval "use ecommerce_logs; db.uploads.aggregate([{$group: {_id: '$status', count: {$sum: 1}}}])"

# Uploads en erreur
docker-compose exec mongodb mongosh -u admin -p mongodb_password --eval "use ecommerce_logs; db.uploads.find({status: 'failed'}).pretty()"
```

### Logs du Service
```powershell
# Voir les logs en temps rÃ©el
Get-Content backend\ingestion_service.log -Wait

# DerniÃ¨res 50 lignes
Get-Content backend\ingestion_service.log -Tail 50
```

## ğŸ› ï¸ Retry Logic

Le service implÃ©mente une stratÃ©gie de retry robuste:

1. **PremiÃ¨re tentative**: Traitement immÃ©diat
2. **Ã‰chec**: Attente 5 secondes â†’ Retry 1
3. **Ã‰chec**: Attente 5 secondes â†’ Retry 2
4. **Ã‰chec**: Attente 5 secondes â†’ Retry 3
5. **Ã‰chec final**: Marque job comme `failed` dans MongoDB

**Informations MongoDB en cas d'Ã©chec**:
```json
{
  "job_id": "abc-123",
  "status": "failed",
  "error_message": "Max retries exceeded: File not found",
  "retry_count": 3,
  "failed_at": "2025-12-25T10:05:45Z"
}
```

## ğŸ“Š MÃ©triques & Stats

Le service log les mÃ©triques suivantes:
- Nombre de jobs traitÃ©s
- Temps de traitement par job
- Nombre de retries
- Taux de succÃ¨s/Ã©chec
- Longueur de la queue

## ğŸ› Troubleshooting

### Service ne dÃ©marre pas
```powershell
# VÃ©rifier Redis
docker-compose exec redis redis-cli -a redis_password PING

# VÃ©rifier MongoDB
docker-compose exec mongodb mongosh -u admin -p mongodb_password --eval "db.adminCommand('ping')"

# VÃ©rifier config
python -c "from backend.config import get_config; print(get_config().REDIS_CONFIG)"
```

### Jobs bloquÃ©s dans la queue
```powershell
# Voir les jobs
docker-compose exec redis redis-cli -a redis_password LRANGE ingest_jobs 0 -1

# RedÃ©marrer le service avec logs dÃ©taillÃ©s
cd backend
python start_ingestion_service.py
```

### Fichiers non traitÃ©s par Logstash
```powershell
# VÃ©rifier que Logstash surveille le bon rÃ©pertoire
docker-compose exec logstash cat /usr/share/logstash/pipeline/pipeline_json.conf | grep "path =>"

# Voir logs Logstash
docker-compose logs -f logstash | Select-String "processed"

# VÃ©rifier permissions fichiers
Get-ChildItem uploads\ | Select-Object Name, Length, LastWriteTime
```

## ğŸ” SÃ©curitÃ© & Production

### Recommandations
1. **Permissions fichiers**: Limiter accÃ¨s Ã  `./uploads/`
2. **Validation**: Le service vÃ©rifie l'existence des fichiers
3. **Error handling**: Toutes les exceptions sont catchÃ©es et loggÃ©es
4. **Graceful shutdown**: Signal handlers pour arrÃªt propre
5. **Monitoring**: Configurer alertes sur logs `ERROR` et `CRITICAL`

### DÃ©ploiement Production
```powershell
# En tant que service Windows (avec NSSM)
nssm install IngestionService "C:\Python\python.exe" "C:\projet_bigdata\backend\start_ingestion_service.py"
nssm set IngestionService AppDirectory "C:\projet_bigdata\backend"
nssm start IngestionService

# Ou avec Task Scheduler (dÃ©marrage automatique)
```

## ğŸ“ Fichiers SupprimÃ©s

- âŒ `backend/app/tasks/log_tasks.py` - TÃ¢ches Celery incomplÃ¨tes, remplacÃ©es par service autonome
- âœ… Service autonome plus simple et robuste sans dÃ©pendance Celery

## ğŸ¯ Avantages du Service Autonome

ComparÃ© aux tÃ¢ches Celery:
- âœ… **Plus simple**: Pas besoin de Celery worker
- âœ… **Plus rapide**: Ã‰coute en continu (polling 5s vs dÃ©clenchement manuel)
- âœ… **Plus robuste**: Retry logic intÃ©grÃ©e
- âœ… **Meilleur monitoring**: Logs dÃ©taillÃ©s en temps rÃ©el
- âœ… **Graceful shutdown**: Gestion propre des signaux
- âœ… **Standalone**: Peut tourner indÃ©pendamment de Flask

## ğŸ“š RÃ©fÃ©rences

- Code source: [`backend/ingestion_service.py`](backend/ingestion_service.py)
- Tests: [`test_ingestion_service.py`](test_ingestion_service.py)
- DÃ©marrage: [`backend/start_ingestion_service.py`](backend/start_ingestion_service.py)
