# üöÄ Impl√©mentation du Cache Redis pour Elasticsearch

## Vue d'ensemble

Le syst√®me de cache Redis optimise les performances des recherches Elasticsearch en mettant en cache les r√©sultats des requ√™tes fr√©quentes.

## ‚úÖ Fonctionnalit√©s impl√©ment√©es

### 1. G√©n√©ration de cl√© de cache

**Fichier**: `backend/app/services/search_service.py`

```python
def _generate_cache_key(self, **params):
    """
    G√©n√®re une cl√© de cache unique bas√©e sur les param√®tres de recherche
    
    - Trie les param√®tres pour coh√©rence
    - Filtre les valeurs None
    - G√©n√®re un hash MD5
    - Format: search:<hash>
    """
    sorted_params = sorted(params.items())
    filtered_params = [(k, v) for k, v in sorted_params if v is not None]
    params_str = json.dumps(filtered_params, sort_keys=True)
    hash_obj = hashlib.md5(params_str.encode())
    return f"search:{hash_obj.hexdigest()}"
```

**Exemple de cl√©**: `search:66cf40faa150b0e121444428e6a186ec`

### 2. Stockage des r√©sultats avec TTL

**TTL configur√©**: 60 secondes par d√©faut

```python
# Cache results with 60 seconds TTL
self.redis_service.set(cache_key, search_results, ttl=60)
logger.debug(f"Cached search results: {cache_key}")
```

**Donn√©es mises en cache**:
- R√©sultats de recherche complets
- M√©tadonn√©es de pagination (total, page, total_pages)
- Filtres appliqu√©s
- Param√®tres de tri

### 3. Lecture depuis le cache

```python
# Try to get from cache
cached_result = self.redis_service.get(cache_key)
if cached_result:
    logger.info(f"Cache HIT for search: {cache_key}")
    cached_result['cached'] = True
    return cached_result

logger.info(f"Cache MISS for search: {cache_key}")
```

**Indicateur dans la r√©ponse**:
```json
{
  "cached": true,
  "total": 40,
  "results": [...],
  "page": 1
}
```

### 4. Invalidation du cache

**Fichier**: `backend/app/services/redis_service.py`

```python
def delete_pattern(self, pattern):
    """
    Supprime toutes les cl√©s correspondant √† un pattern
    Utilise SCAN pour it√©rer efficacement
    """
    deleted_count = 0
    cursor = 0
    
    while True:
        cursor, keys = self.client.scan(cursor, match=pattern, count=100)
        if keys:
            deleted_count += self.client.delete(*keys)
        if cursor == 0:
            break
    
    logger.info(f"Deleted {deleted_count} keys matching pattern: {pattern}")
    return deleted_count
```

**D√©clencheurs d'invalidation**:

1. **Upload de fichier** (`process_upload_with_preview`):
```python
# Invalidate search cache on new upload
self.redis_service.delete_pattern('search:*')
logger.info("Invalidated all search caches due to new upload")
```

2. **Traitement de logs** (`process_log_file`):
```python
# Invalidate cache
self.redis_service.delete('logs:recent')
self.redis_service.delete('logs:stats')
self.redis_service.delete_pattern('search:*')
```

3. **Ingestion de logs** (`ingest_logs`):
```python
# Invalidate cache
self.redis_service.delete_pattern('search:*')
logger.info("Invalidated caches due to log ingestion")
```

## üìä Performances mesur√©es

### Tests de performance

```
Test 1: Premi√®re recherche (CACHE MISS)
  Temps: 205ms
  Cached: False
  R√©sultats: 40 logs

Test 2: M√™me recherche (CACHE HIT)
  Temps: 43ms
  Cached: True
  R√©sultats: 40 logs

Am√©lioration: 78.9% üöÄ
```

### Logs Redis

```
INFO - Cache MISS for search: search:66cf40faa150b0e121444428e6a186ec
INFO - Executing search: query='payment', page=1, size=20
INFO - Cache HIT for search: search:66cf40faa150b0e121444428e6a186ec
INFO - Cache HIT for search: search:66cf40faa150b0e121444428e6a186ec
```

## üîß Configuration

### Variables d'environnement

```env
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_PASSWORD=changeme
```

### Configuration du cache

```python
# dans RedisService.__init__
self.cache_ttl = config.get('cache_ttl', 3600)  # 1 heure par d√©faut

# dans SearchService.search
self.redis_service.set(cache_key, search_results, ttl=60)  # 60 secondes pour les recherches
```

## üìù Int√©gration dans l'API

### Endpoint de recherche

**Route**: `POST /api/logs/search`

**Avant optimisation**:
```python
# Direct Elasticsearch query (sans cache)
result = current_app.es_service.search('logs', query)
```

**Apr√®s optimisation**:
```python
# Utilisation du SearchService avec cache
search_service = SearchService(
    current_app.es_service,
    current_app.redis_service,
    current_app.mongo_service
)

search_results = search_service.search(
    query=query_text,
    level=level,
    service=service,
    ...
)
```

### R√©ponse API enrichie

```json
{
  "success": true,
  "results": [...],
  "total": 40,
  "count": 10,
  "cached": true,
  "page": 1,
  "total_pages": 4
}
```

## üêõ Corrections apport√©es

### 1. QueryBuilder - Champs num√©riques

**Probl√®me**: Les champs `user_id`, `order_id`, `transaction_id` sont de type `long` dans Elasticsearch mais trait√©s comme texte avec fuzzy matching.

**Solution**: 
- Retrait des champs num√©riques du `multi_match`
- Traitement sp√©cial pour `user_id` dans les filtres

```python
# Avant
"fields": [
    "message^3",
    "user_id",      # ‚ùå Cause fuzzy query error
    "order_id",     # ‚ùå Type long
    "transaction_id" # ‚ùå Type long
]

# Apr√®s
"fields": [
    "message^3",
    "error_message^2",
    "endpoint",
    "service"
]
```

### 2. Filtre user_id adaptatif

```python
def with_user_filter(self, user_id):
    try:
        # Essayer conversion en int pour type long
        user_id_value = int(user_id_clean)
        self.query["query"]["bool"]["filter"].append({
            "term": {"user_id": user_id_value}
        })
    except ValueError:
        # Sinon traiter comme keyword
        self.query["query"]["bool"]["filter"].append({
            "term": {"user_id.keyword": user_id_clean}
        })
```

## üß™ Tests

### Test manuel avec curl

```bash
# Premi√®re recherche (MISS)
curl -X POST http://localhost:5001/api/logs/search \
  -H "Content-Type: application/json" \
  -d '{"query":"error","size":10}'

# Deuxi√®me recherche (HIT)
curl -X POST http://localhost:5001/api/logs/search \
  -H "Content-Type: application/json" \
  -d '{"query":"error","size":10}'
```

### Test d'invalidation

```bash
# 1. Recherche pour remplir le cache
curl -X POST http://localhost:5001/api/logs/search \
  -H "Content-Type: application/json" \
  -d '{"query":"test","size":10}'

# 2. Upload d'un fichier (invalide le cache)
curl -X POST http://localhost:5001/api/logs/upload \
  -H "Authorization: Bearer <token>" \
  -F "file=@test_logs.json"

# 3. M√™me recherche (MISS car cache invalid√©)
curl -X POST http://localhost:5001/api/logs/search \
  -H "Content-Type: application/json" \
  -d '{"query":"test","size":10}'
```

### V√©rification des cl√©s Redis

```bash
# Connexion √† Redis
docker exec -it redis redis-cli

# Liste des cl√©s de cache
KEYS search:*

# Voir une cl√© sp√©cifique
GET search:66cf40faa150b0e121444428e6a186ec

# TTL d'une cl√©
TTL search:66cf40faa150b0e121444428e6a186ec
```

## ‚úÖ Crit√®res d'acceptation

| Crit√®re | Statut | D√©tails |
|---------|--------|---------|
| ‚úÖ G√©n√©ration de cl√© bas√©e sur param√®tres | Valid√© | MD5 hash avec tri des param√®tres |
| ‚úÖ Stockage avec TTL configurable | Valid√© | 60s pour recherches, 3600s par d√©faut |
| ‚úÖ Lecture depuis cache si disponible | Valid√© | Indicateur `cached` dans r√©ponse |
| ‚úÖ Invalidation lors d'uploads | Valid√© | Pattern `search:*` supprim√© |
| ‚úÖ Requ√™tes r√©p√©t√©es plus rapides | Valid√© | **78.9% d'am√©lioration** |
| ‚úÖ Redis effectivement utilis√© | Valid√© | Logs confirm√©s (HIT/MISS) |

## üìà Impact

### Avant
- Toutes les recherches interrogent Elasticsearch
- Temps de r√©ponse: ~200ms par recherche
- Charge √©lev√©e sur Elasticsearch

### Apr√®s
- Premi√®re recherche: ~200ms (MISS)
- Recherches suivantes: ~40ms (HIT)
- **R√©duction de 78.9% du temps de r√©ponse**
- **R√©duction de la charge Elasticsearch**

## üîÆ Am√©liorations futures

1. **Cache stratifi√©**:
   - Court terme: 60s pour r√©sultats volatiles
   - Long terme: 1h pour agr√©gations
   
2. **Invalidation s√©lective**:
   - Invalider uniquement les recherches concern√©es
   - Conserver les caches non affect√©s

3. **Statistiques de cache**:
   - Hit rate monitoring
   - Cache size tracking
   - Performance analytics

4. **Pre-warming**:
   - Pr√©-charger les recherches fr√©quentes
   - Cache des top 10 queries

## üìö R√©f√©rences

- **Redis**: `backend/app/services/redis_service.py`
- **SearchService**: `backend/app/services/search_service.py`
- **LogService**: `backend/app/services/log_service.py`
- **Routes**: `backend/app/routes/logs_routes.py`
- **QueryBuilder**: `backend/app/utils/query_builder.py`

---

**Version**: 2.0.0  
**Date**: Janvier 2026  
**Statut**: ‚úÖ Production Ready
